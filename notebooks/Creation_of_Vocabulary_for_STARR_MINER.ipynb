{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of Vocabulary for STARR-MINER\n",
    "\n",
    "This notebooks contains the code to create the vocabulary used for our STARR-MINER framework. To get more deatils about this framework and how it is used to populate the NOTE_NLP table in STARR-OMOP feel free to refer to our pre-print [here](https://arxiv.org/abs/2003.10534)\n",
    "\n",
    "Below are the steps to create a new vocabulary\n",
    "1. Filter the lexicons for:\n",
    "    - Stopwords\n",
    "    - Very long and short characters\n",
    "    - Only numbers\n",
    "    - Concept names with non alphanumeric characters in certain positions\n",
    "    - Select a subset of vocabularies present in the OHDSI vocabulary. \n",
    "2. The primary key is the lowercased version of MRCONSO.STR \n",
    "3. We map from CUI's to concept_id a SQL code developed in the OHDSI package [Ananke](https://github.com/jmbanda/Ananke). \n",
    "\n",
    "The paper that describes some of the steps taken here to filter UMLS to produce a vocabulary to be used with clinical NLP pipelines can be found [here](https://pubmed.ncbi.nlm.nih.gov/22493050/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "json_path = \"/Users/jdposada/.config/gcloud/application_default_credentials.json\"\n",
    "service_account_path = \"/Users/jdposada/Documents/secret\"\n",
    "cdm_project_id = 'som-rit-phi-starr-prod'\n",
    "cdm_dataset_id = 'starr_omop_cdm5_deid_latest'\n",
    "omop_vocab_dataset_id = 'vocabulary_20200811'\n",
    "work_project_id = 'som-rit-phi-starr-miner-dev'\n",
    "work_dataset_id = 'jdposada_explore'\n",
    "umls_dataset_id = 'umls_2019AA'\n",
    "starr_miner_vocab_name = '20200831_textu2_concept_mapping'\n",
    "csv_files_folder = \"../resources\"\n",
    "sql_files_folder = \"../resources\"\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = json_path\n",
    "os.environ['GCLOUD_PROJECT'] = work_project_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "job_config = bigquery.QueryJobConfig(default_dataset=f\"{work_project_id}.{work_dataset_id}\")\n",
    "client = bigquery.Client(project=work_project_id, default_query_job_config=job_config);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters based on char length, words, only numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the parenthesis list**. This is names that contains string like uta (disorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "parenthesis_list = open(f\"{csv_files_folder}/parenthesis_list.csv\", 'r').readlines()\n",
    "parenthesis_list = [re.sub(r'\\n', '', x) for x in parenthesis_list]\n",
    "parenthesis_list = '|'.join(parenthesis_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read and update stopwords with spacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stopwords_list = open(f\"{csv_files_folder}/stopwords.csv\", encoding='utf-8', mode='r+').readlines()\n",
    "stopwords_list = [re.sub(r'\\n', '', x.lower()) for x in stopwords_list]\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "stopwords_list = list(set(stopwords_list).union(set(STOP_WORDS)))\n",
    "stopwords_list.sort()\n",
    "with open('stopwords.csv',encoding='utf-8', mode='w+') as f:\n",
    "    [f.write(x + '\\n') for x in stopwords_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upoload to BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stopwords_list_df = pd.DataFrame({'stopword': stopwords_list})\n",
    "client.load_table_from_dataframe(dataframe = stopwords_list_df, \n",
    "                                 destination = f'{work_project_id}.{work_dataset_id}.stopwords');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the list of vocabularies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocabularies_df = pd.read_csv(f\"{csv_files_folder}/sab_list.csv\")\n",
    "sab_list = vocabularies_df['SAB'].values.tolist()\n",
    "sab_list = \"('\" + \"','\".join(sab_list) + \"')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_list = [x.split('\\n')[0] for x in open(f\"{csv_files_folder}/regex_list.txt\", 'r').readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the SQL string and execute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 15.3 ms, sys: 3.36 ms, total: 18.6 ms\nWall time: 27.7 s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f843bd12da0>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "%%time\n",
    "sql = \"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    "  `{work_project_id}.{work_dataset_id}.mrconso_filtered` AS\n",
    "SELECT\n",
    "  *\n",
    "FROM (\n",
    "  SELECT\n",
    "    mrconso.sui,\n",
    "    mrconso.cui,\n",
    "    mrconso.code,\n",
    "    mrconso.lat,\n",
    "    mrsty.tui,\n",
    "    mrsty.sty,\n",
    "    mrconso.sab,\n",
    "    mrconso.str,\n",
    "    LOWER(str) AS lowerstr,\n",
    "    LENGTH(str) AS charlen,\n",
    "    ARRAY_LENGTH(REGEXP_EXTRACT_ALL(str, '\\\\\\S{{1,}}')) AS word_count\n",
    "  FROM\n",
    "    `{work_project_id}.{umls_dataset_id}.MRCONSO` mrconso\n",
    "  JOIN\n",
    "  `{work_project_id}.{umls_dataset_id}.MRSTY` mrsty\n",
    "   ON\n",
    "    mrsty.cui = mrconso.cui\n",
    "  WHERE\n",
    "    lat = 'ENG' -- 10,406,797\n",
    "    AND mrconso.SAB in {sab_list}\n",
    "    AND NOT REGEXP_CONTAINS(str, r'{rgx[0]}') \n",
    "    AND NOT REGEXP_CONTAINS(str, r'{rgx[1]}') \n",
    "    AND NOT REGEXP_CONTAINS(str, r'{rgx[2]}') \n",
    "    AND NOT REGEXP_CONTAINS(LOWER(str), r'\\({parenthesis_list}\\)') \n",
    "    AND LOWER(str) NOT IN \n",
    "    (SELECT \n",
    "      LOWER(stopword) \n",
    "     FROM\n",
    "      `{work_project_id}.{work_dataset_id}.stopwords`)\n",
    "    )\n",
    "WHERE\n",
    "  charlen > 2 \n",
    "  AND charlen < 56 \n",
    "  AND word_count < 7 \n",
    "\"\"\".format_map({'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id,\n",
    "                'umls_dataset_id': umls_dataset_id,\n",
    "                'parenthesis_list': parenthesis_list,\n",
    "                'sab_list': sab_list,\n",
    "                'rgx': regex_list})\n",
    "\n",
    "client.query(sql).result();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the concept_id to CUI mappings from Ananke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the vocab to the work project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_ref = client.dataset(dataset_id=omop_vocab_dataset_id, \n",
    "                             project=cdm_project_id)\n",
    "table_list = client.list_tables(dataset_ref)\n",
    "tables = [x for x in table_list]\n",
    "table_id_list = [x.table_id for x in tables]\n",
    "\n",
    "# create the destination dataset\n",
    "client.create_dataset(f\"{work_project_id}.{omop_vocab_dataset_id}\", exists_ok=True)\n",
    "dest_dataset_ref = client.dataset(dataset_id=omop_vocab_dataset_id, \n",
    "                                  project=work_project_id)\n",
    "for table_id in table_id_list:\n",
    "    source_table_ref = dataset_ref.table(table_id)\n",
    "    dest_table_ref = dest_dataset_ref.table(table_id)\n",
    "    job_config = bigquery.CopyJobConfig()\n",
    "    job_config.write_disposition = bigquery.job.WriteDisposition.WRITE_TRUNCATE\n",
    "    job = client.copy_table(\n",
    "        source_table_ref,\n",
    "        dest_table_ref,\n",
    "        # Location must match that of the source and destination tables.\n",
    "        location='US',\n",
    "        job_config=job_config)\n",
    "    job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sql_map = open(f\"{sql_files_folder}/cui2ohdsi_concept_idv1.1_mod.sql\", 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sql_map = re.sub(pattern = r'OHDSIVocab.OHDSI_to_CUI_TEMP', \n",
    "                 repl= f\"`{work_project_id}.{omop_vocab_dataset_id}.ohdsi_to_cui_temp`\", \n",
    "                 string = sql_map)\n",
    "\n",
    "sql_map = re.sub(pattern = r'OHDSIVocab.OHDSI_to_CUI', \n",
    "                 repl= f\"`{work_project_id}.{omop_vocab_dataset_id}.ohdsi_to_cui`\", \n",
    "                 string = sql_map)\n",
    "\n",
    "sql_map = re.sub(pattern = r'OHDSIVocab.concept', \n",
    "                 repl= f\"`{work_project_id}.{omop_vocab_dataset_id}.concept`\", \n",
    "                 string = sql_map)\n",
    "\n",
    "sql_map = re.sub(pattern = r'umls.MRCONSO', \n",
    "                 repl= f\"`{work_project_id}.{work_dataset_id}.mrconso_filtered`\", \n",
    "                 string = sql_map)\n",
    "\n",
    "sql_map = re.sub(pattern = r'UNION', \n",
    "                 repl= \"UNION ALL\", \n",
    "                 string = sql_map)\n",
    "\n",
    "sql_map = re.sub(pattern = r'GROUP BY AA.CUI', \n",
    "                 repl= \"GROUP BY AA.CUI, AA.concept_id, AA.vocabulary_id\", \n",
    "                 string = sql_map)\n",
    "\n",
    "sql_map = re.sub(pattern = r'GROUP BY A.CUI', \n",
    "                 repl= \"GROUP BY A.CUI, B.concept_id\", \n",
    "                 string = sql_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally create the mappings. This creates a table called ohdsi_to_cui**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 30.5 ms, sys: 5.96 ms, total: 36.5 ms\nWall time: 2min 38s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f843bdbae80>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "%%time\n",
    "client.query(sql_map).result();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's do the join and get each string a concept_id**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 15.1 ms, sys: 3.17 ms, total: 18.3 ms\nWall time: 25.4 s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f843b124400>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "%%time\n",
    "sql = \"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    " `{work_project_id}.{work_dataset_id}.mrconso_filtered_concept_id` AS\n",
    "SELECT\n",
    " mrconso.*,\n",
    " map_.concept_id\n",
    "FROM\n",
    "  `{work_project_id}.{work_dataset_id}.mrconso_filtered` mrconso\n",
    "JOIN\n",
    "  `{work_project_id}.{omop_vocab_dataset_id}.ohdsi_to_cui` map_\n",
    "ON\n",
    "  mrconso.cui = map_.cui\n",
    "\"\"\".format_map({'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id,\n",
    "                'omop_vocab_dataset_id': omop_vocab_dataset_id})\n",
    "\n",
    "client.query(sql).result();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create the final dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 16.7 ms, sys: 3.43 ms, total: 20.1 ms\nWall time: 44.8 s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f843bd38ba8>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "%%time\n",
    "sql = \"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    " `{work_project_id}.{work_dataset_id}.temp_starr_miner_vocab` AS\n",
    "SELECT\n",
    " ROW_NUMBER() OVER() AS concept_index,\n",
    " ARRAY_AGG(DISTINCT concept_id) AS concept_id_array,\n",
    " lowerstr\n",
    "FROM\n",
    "  `{work_project_id}.{work_dataset_id}.mrconso_sui_concept_id`\n",
    "GROUP BY\n",
    " lowerstr;\n",
    "\n",
    "CREATE OR REPLACE TABLE\n",
    " `{work_project_id}.{work_dataset_id}.{starr_miner_vocab_name}` AS\n",
    "SELECT\n",
    "  concept_index,\n",
    "  concept_id,\n",
    "  lowerstr\n",
    "FROM\n",
    "  `{work_project_id}.{work_dataset_id}.temp_starr_miner_vocab` as t\n",
    "CROSS JOIN\n",
    "  UNNEST(t.concept_id_array) AS concept_id;\n",
    "  \n",
    "CREATE OR REPLACE TABLE\n",
    " `{work_project_id}.{work_dataset_id}.{starr_miner_vocab_name}` AS\n",
    "SELECT\n",
    "  concept_index,\n",
    "  concept_id,\n",
    "  COALESCE(cr.concept_id_2, 0) AS standard_concept_id,\n",
    "  lowerstr\n",
    "FROM\n",
    "  `{work_project_id}.{work_dataset_id}.{starr_miner_vocab_name}` as t\n",
    "LEFT JOIN\n",
    " `{work_project_id}.{omop_vocab_dataset_id}.concept_relationship` cr\n",
    "ON\n",
    " cr.concept_id_1 = t.concept_id\n",
    " AND cr.relationship_id = 'Maps to';\n",
    "\n",
    "DROP TABLE IF EXISTS `{work_project_id}.{work_dataset_id}.temp_starr_miner_vocab`;\n",
    "\n",
    "\"\"\".format_map({'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id,\n",
    "                'starr_miner_vocab_name': starr_miner_vocab_name,\n",
    "                'omop_vocab_dataset_id': omop_vocab_dataset_id})\n",
    "\n",
    "client.query(sql).result();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove again stopwords again that could have been brought in after all the prior joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    " `{work_project_id}.{work_dataset_id}.{starr_miner_vocab_name}` AS\n",
    "SELECT\n",
    " vocab.*\n",
    "FROM\n",
    " `{work_project_id}.{work_dataset_id}.{starr_miner_vocab_name}` vocab\n",
    "LEFT JOIN\n",
    " `{work_project_id}.{work_dataset_id}.stopwords` stopwords\n",
    "ON\n",
    " stopwords.stopword = vocab.lowerstr\n",
    "WHERE \n",
    " stopwords.stopword is NULL\n",
    "\"\"\".format_map({'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id,\n",
    "                'starr_miner_vocab_name': starr_miner_vocab_name})\n",
    "\n",
    "client.query(sql).result();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check none of the stopwords are actually in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   counts\n0       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "SELECT\n",
    " COUNT(1) AS counts\n",
    "FROM\n",
    " `{work_project_id}.{work_dataset_id}.{starr_miner_vocab_name}` vocab\n",
    "JOIN\n",
    " `{work_project_id}.{work_dataset_id}.stopwords` stopwords\n",
    "ON\n",
    " stopwords.stopword = vocab.lowerstr\n",
    "\"\"\".format_map({'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id,\n",
    "                'starr_miner_vocab_name': starr_miner_vocab_name})\n",
    "\n",
    "df = client.query(sql).to_dataframe();\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check how many rows do we get and how the final dictionary looks like**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT\n",
    " COUNT(DISTINCT lowerstr) n_unique_strings,\n",
    " COUNT(DISTINCT concept_id) n_unique_concept_id,\n",
    " COUNT(DISTINCT standard_concept_id) n_unique_standard_concept_id\n",
    "FROM\n",
    " `{work_project_id}.{work_dataset_id}.{starr_miner_vocab_name}`\n",
    "\"\"\".format_map({'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id,\n",
    "                'starr_miner_vocab_name': starr_miner_vocab_name,\n",
    "                'omop_vocab_dataset_id': omop_vocab_dataset_id})\n",
    "\n",
    "df = client.query(sql).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   n_unique_strings  n_unique_concept_id  n_unique_standard_concept_id\n0            989293               749337                        466891",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_unique_strings</th>\n      <th>n_unique_concept_id</th>\n      <th>n_unique_standard_concept_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>989293</td>\n      <td>749337</td>\n      <td>466891</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how the vocab looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT * \n",
    "FROM\n",
    " `{work_project_id}.{work_dataset_id}.{starr_miner_vocab_name}`\n",
    "LIMIT 5\n",
    "\"\"\".format_map({'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id,\n",
    "                'starr_miner_vocab_name': starr_miner_vocab_name,\n",
    "                'omop_vocab_dataset_id': omop_vocab_dataset_id})\n",
    "\n",
    "df = client.query(sql).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   concept_index  concept_id  standard_concept_id  \\\n0         784384    44782969             44782969   \n1         683161    45956813              4294611   \n2         581266     4107542              4107542   \n3         707583    37109601             37109601   \n4         752513       73075                73075   \n\n                             lowerstr  \n0        lymphoedema due to infection  \n1       modified-release oral capsule  \n2         glycogen storage disease ib  \n3                   genus siccibacter  \n4  superficial bruising of upper limb  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>concept_index</th>\n      <th>concept_id</th>\n      <th>standard_concept_id</th>\n      <th>lowerstr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>784384</td>\n      <td>44782969</td>\n      <td>44782969</td>\n      <td>lymphoedema due to infection</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>683161</td>\n      <td>45956813</td>\n      <td>4294611</td>\n      <td>modified-release oral capsule</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>581266</td>\n      <td>4107542</td>\n      <td>4107542</td>\n      <td>glycogen storage disease ib</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>707583</td>\n      <td>37109601</td>\n      <td>37109601</td>\n      <td>genus siccibacter</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>752513</td>\n      <td>73075</td>\n      <td>73075</td>\n      <td>superficial bruising of upper limb</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('spacy_env': conda)",
   "language": "python",
   "name": "python_defaultSpec_1598903434391"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}