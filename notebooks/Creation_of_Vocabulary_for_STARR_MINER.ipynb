{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of Vocabulary for STARR-MINER\n",
    "\n",
    "This notebooks contains the code to create the vocabulary used for our STARR-MINER framework. To get more deatils about this framework and how it is used to populate the NOTE_NLP table in STARR-OMOP feel free to refer to our pre-print [here](https://arxiv.org/abs/2003.10534)\n",
    "\n",
    "Below are the steps to create a new vocabulary\n",
    "1. Filter the lexicons for:\n",
    "    - Stopwords\n",
    "    - Very long and short characters\n",
    "    - Only numbers\n",
    "    - Concept names with non alphanumeric characters in certain positions\n",
    "    - Select a subset of vocabularies present in the OHDSI vocabulary. \n",
    "2. The primary key is the lowercased version of MRCONSO.STR \n",
    "3. We map from CUI's to concept_id a SQL code developed in the OHDSI package [Ananke](https://github.com/jmbanda/Ananke). \n",
    "\n",
    "The paper that describes some of the steps taken here to filter UMLS to produce a vocabulary to be used with clinical NLP pipelines can be found [here](https://pubmed.ncbi.nlm.nih.gov/22493050/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import spacy\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "json_path = \"/Users/jdposada/.config/gcloud/application_default_credentials.json\"\n",
    "service_account_path = \"/Users/jdposada/Documents/secret\"\n",
    "cdm_project_id = 'som-rit-phi-starr-prod'\n",
    "cdm_dataset_id = 'starr_omop_cdm5_deid_latest'\n",
    "omop_vocab_dataset_id = 'vocabulary_20200717'\n",
    "work_project_id = 'som-rit-phi-starr-miner-dev'\n",
    "work_dataset_id = 'jdposada_explore'\n",
    "umls_dataset_id = 'umls_2019AA'\n",
    "starr_miner_vocab_name = '20200805_starr_miner_dictionary'\n",
    "csv_files_folder = \"../resources\"\n",
    "sql_files_folder = \"../resources\"\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = json_path\n",
    "os.environ['GCLOUD_PROJECT'] = work_project_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "client = bigquery.Client(project=work_project_id);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters based on char length, words, only numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the parenthesis list**. This is names that contains string like uta (disorder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "parenthesis_list = open(f\"{csv_files_folder}/parenthesis_list.csv\", 'r').readlines()\n",
    "parenthesis_list = [re.sub(r'\\n', '', x) for x in parenthesis_list]\n",
    "parenthesis_list = '|'.join(parenthesis_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read and update stopwords with spacy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stopwords_list = open(f\"{csv_files_folder}/stopwords.csv\", encoding='utf-8', mode='r+').readlines()\n",
    "stopwords_list = [re.sub(r'\\n', '', x.lower()) for x in stopwords_list]\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "stopwords_list = list(set(stopwords_list).union(set(STOP_WORDS)))\n",
    "stopwords_list.sort()\n",
    "with open('stopwords.csv',encoding='utf-8', mode='w+') as f:\n",
    "    [f.write(x + '\\n') for x in stopwords_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upoload to BQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "stopwords_list_df = pd.DataFrame({'stopword': stopwords_list})\n",
    "client.load_table_from_dataframe(dataframe = stopwords_list_df, \n",
    "                                 destination = f'{work_project_id}.{work_dataset_id}.stopwords');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Read the list of vocabularies**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "vocabularies_df = pd.read_csv(f\"{csv_files_folder}/sab_list.csv\")\n",
    "sab_list = vocabularies_df['SAB'].values.tolist()\n",
    "sab_list = \"('\" + \"','\".join(sab_list) + \"')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex_list = [x.split('\\n')[0] for x in open(f\"{csv_files_folder}/regex_list.txt\", 'r').readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create the SQL string and execute**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 31.8 ms, sys: 5.44 ms, total: 37.3 ms\nWall time: 1min 26s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f918943d0f0>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "%%time\n",
    "sql = \"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    "  `{work_project_id}.{work_dataset_id}.mrconso_filtered` AS\n",
    "SELECT\n",
    "  *\n",
    "FROM (\n",
    "  SELECT\n",
    "    mrconso.sui,\n",
    "    mrconso.cui,\n",
    "    mrconso.code,\n",
    "    mrconso.lat,\n",
    "    mrsty.tui,\n",
    "    mrsty.sty,\n",
    "    mrconso.sab,\n",
    "    mrconso.str,\n",
    "    LOWER(str) AS lowerstr,\n",
    "    LENGTH(str) AS charlen,\n",
    "    ARRAY_LENGTH(REGEXP_EXTRACT_ALL(str, '\\\\\\S{{1,}}')) AS word_count\n",
    "  FROM\n",
    "    `{work_project_id}.{umls_dataset_id}.MRCONSO` mrconso\n",
    "  JOIN\n",
    "  `{work_project_id}.{umls_dataset_id}.MRSTY` mrsty\n",
    "   ON\n",
    "    mrsty.cui = mrconso.cui\n",
    "  WHERE\n",
    "    lat = 'ENG' -- 10,406,797\n",
    "    AND mrconso.SAB in {sab_list}\n",
    "    AND NOT REGEXP_CONTAINS(str, r'{rgx[0]}') \n",
    "    AND NOT REGEXP_CONTAINS(str, r'{rgx[1]}') \n",
    "    AND NOT REGEXP_CONTAINS(str, r'{rgx[2]}') \n",
    "    AND NOT REGEXP_CONTAINS(LOWER(str), r'\\({parenthesis_list}\\)') \n",
    "    AND LOWER(str) NOT IN \n",
    "    (SELECT \n",
    "      LOWER(stopword) \n",
    "     FROM\n",
    "      `{work_project_id}.{work_dataset_id}.stopwords`)\n",
    "    )\n",
    "WHERE\n",
    "  charlen > 2 \n",
    "  AND charlen < 56 \n",
    "  AND word_count < 7 \n",
    "\"\"\".format_map({'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id,\n",
    "                'umls_dataset_id': umls_dataset_id,\n",
    "                'parenthesis_list': parenthesis_list,\n",
    "                'sab_list': sab_list,\n",
    "                'rgx': regex_list})\n",
    "\n",
    "client.query(sql).result();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the concept_id to CUI mappings from Ananke"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copy the vocab to the work project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dataset_ref = client.dataset(dataset_id=omop_vocab_dataset_id, \n",
    "                             project=cdm_project_id)\n",
    "table_list = client.list_tables(dataset_ref)\n",
    "tables = [x for x in table_list]\n",
    "table_id_list = [x.table_id for x in tables]\n",
    "\n",
    "# create the destination dataset\n",
    "client.create_dataset(f\"{work_project_id}.{omop_vocab_dataset_id}\", exists_ok=True)\n",
    "dest_dataset_ref = client.dataset(dataset_id=omop_vocab_dataset_id, \n",
    "                                  project=work_project_id)\n",
    "for table_id in table_id_list:\n",
    "    source_table_ref = dataset_ref.table(table_id)\n",
    "    dest_table_ref = dest_dataset_ref.table(table_id)\n",
    "    job_config = bigquery.CopyJobConfig()\n",
    "    job_config.write_disposition = bigquery.job.WriteDisposition.WRITE_TRUNCATE\n",
    "    job = client.copy_table(\n",
    "        source_table_ref,\n",
    "        dest_table_ref,\n",
    "        # Location must match that of the source and destination tables.\n",
    "        location='US',\n",
    "        job_config=job_config)\n",
    "    job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sql_map = open(f\"{sql_files_folder}/cui2ohdsi_concept_idv1.1_mod.sql\", 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sql_map = re.sub(pattern = r'OHDSIVocab.OHDSI_to_CUI_TEMP', \n",
    "                 repl= f\"`{work_project_id}.{omop_vocab_dataset_id}.ohdsi_to_cui_temp`\", \n",
    "                 string = sql_map)\n",
    "\n",
    "sql_map = re.sub(pattern = r'OHDSIVocab.OHDSI_to_CUI', \n",
    "                 repl= f\"`{work_project_id}.{omop_vocab_dataset_id}.ohdsi_to_cui`\", \n",
    "                 string = sql_map)\n",
    "\n",
    "sql_map = re.sub(pattern = r'OHDSIVocab.concept', \n",
    "                 repl= f\"`{work_project_id}.{omop_vocab_dataset_id}.concept`\", \n",
    "                 string = sql_map)\n",
    "\n",
    "sql_map = re.sub(pattern = r'umls.MRCONSO', \n",
    "                 repl= f\"`{work_project_id}.{work_dataset_id}.mrconso_filtered`\", \n",
    "                 string = sql_map)\n",
    "\n",
    "sql_map = re.sub(pattern = r'UNION', \n",
    "                 repl= \"UNION ALL\", \n",
    "                 string = sql_map)\n",
    "\n",
    "sql_map = re.sub(pattern = r'GROUP BY AA.CUI', \n",
    "                 repl= \"GROUP BY AA.CUI, AA.concept_id, AA.vocabulary_id\", \n",
    "                 string = sql_map)\n",
    "\n",
    "sql_map = re.sub(pattern = r'GROUP BY A.CUI', \n",
    "                 repl= \"GROUP BY A.CUI, B.concept_id\", \n",
    "                 string = sql_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finally create the mappings. This creates a table called ohdsi_to_cui**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 39 ms, sys: 7.87 ms, total: 46.8 ms\nWall time: 3min 13s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f9182e4c6a0>"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "%%time\n",
    "client.query(sql_map).result();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now let's do the join and get each string a concept_id**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 17.5 ms, sys: 3.41 ms, total: 20.9 ms\nWall time: 29.3 s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f918945f8d0>"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "%%time\n",
    "sql = \"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    " `{work_project_id}.{work_dataset_id}.mrconso_filtered_concept_id` AS\n",
    "SELECT\n",
    " mrconso.*,\n",
    " map_.concept_id\n",
    "FROM\n",
    "  `{work_project_id}.{work_dataset_id}.mrconso_filtered` mrconso\n",
    "JOIN\n",
    "  `{work_project_id}.{omop_vocab_dataset_id}.ohdsi_to_cui` map_\n",
    "ON\n",
    "  mrconso.cui = map_.cui\n",
    "\"\"\".format_map({'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id,\n",
    "                'omop_vocab_dataset_id': omop_vocab_dataset_id})\n",
    "\n",
    "client.query(sql).result();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's create the final dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 35.6 ms, sys: 6.62 ms, total: 42.3 ms\nWall time: 3min 28s\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<google.cloud.bigquery.table._EmptyRowIterator at 0x7f91894a4668>"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "%%time\n",
    "sql = \"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    " `{work_project_id}.{work_dataset_id}.temp_starr_miner_vocab` AS\n",
    "SELECT\n",
    " ROW_NUMBER() OVER() AS concept_index,\n",
    " ARRAY_AGG(DISTINCT concept_id) AS concept_id_array,\n",
    " lowerstr\n",
    "FROM\n",
    "  `{work_project_id}.{work_dataset_id}.mrconso_sui_concept_id`\n",
    "GROUP BY\n",
    " lowerstr;\n",
    "\n",
    "CREATE OR REPLACE TABLE\n",
    " `{work_project_id}.{work_dataset_id}.{starr_miner_vocab_name}` AS\n",
    "SELECT\n",
    "  concept_index,\n",
    "  concept_id,\n",
    "  lowerstr\n",
    "FROM\n",
    "  `{work_project_id}.{work_dataset_id}.temp_starr_miner_vocab` as t\n",
    "CROSS JOIN\n",
    "  UNNEST(t.concept_id_array) AS concept_id;\n",
    "  \n",
    "CREATE OR REPLACE TABLE\n",
    " `{work_project_id}.{work_dataset_id}.{starr_miner_vocab_name}` AS\n",
    "SELECT\n",
    "  concept_index,\n",
    "  concept_id,\n",
    "  COALESCE(cr.concept_id_2, 0) AS standard_concept_id,\n",
    "  lowerstr\n",
    "FROM\n",
    "  `{work_project_id}.{work_dataset_id}.{starr_miner_vocab_name}` as t\n",
    "LEFT JOIN\n",
    " `{work_project_id}.{omop_vocab_dataset_id}.concept_relationship` cr\n",
    "ON\n",
    " cr.concept_id_1 = t.concept_id\n",
    " AND cr.relationship_id = 'Maps to';\n",
    "\n",
    "DROP TABLE IF EXISTS `{work_project_id}.{work_dataset_id}.temp_starr_miner_vocab`;\n",
    "\n",
    "\"\"\".format_map({'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id,\n",
    "                'starr_miner_vocab_name': starr_miner_vocab_name,\n",
    "                'omop_vocab_dataset_id': omop_vocab_dataset_id})\n",
    "\n",
    "client.query(sql).result();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove again stopwords again that could have been brought in after all the prior joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "CREATE OR REPLACE TABLE\n",
    " `{work_project_id}.{work_dataset_id}.{starr_miner_vocab_name}` AS\n",
    "SELECT\n",
    " vocab.*\n",
    "FROM\n",
    " `{work_project_id}.{work_dataset_id}.{starr_miner_vocab_name}` vocab\n",
    "LEFT JOIN\n",
    " `{work_project_id}.{work_dataset_id}.stopwords` stopwords\n",
    "ON\n",
    " stopwords.stopword = vocab.lowerstr\n",
    "WHERE \n",
    " stopwords.stopword is NULL\n",
    "\"\"\".format_map({'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id,\n",
    "                'starr_miner_vocab_name': starr_miner_vocab_name})\n",
    "\n",
    "client.query(sql).result();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's double check none of the stopwords are actually in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   counts\n0       0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>counts</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "SELECT\n",
    " COUNT(1) AS counts\n",
    "FROM\n",
    " `{work_project_id}.{work_dataset_id}.{starr_miner_vocab_name}` vocab\n",
    "JOIN\n",
    " `{work_project_id}.{work_dataset_id}.stopwords` stopwords\n",
    "ON\n",
    " stopwords.stopword = vocab.lowerstr\n",
    "\"\"\".format_map({'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id,\n",
    "                'starr_miner_vocab_name': starr_miner_vocab_name})\n",
    "\n",
    "df = client.query(sql).to_dataframe();\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check how many rows do we get and how the final dictionary looks like**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT\n",
    " COUNT(DISTINCT lowerstr) n_unique_strings,\n",
    " COUNT(DISTINCT concept_id) n_unique_concept_id,\n",
    " COUNT(DISTINCT standard_concept_id) n_unique_standard_concept_id\n",
    "FROM\n",
    " `{work_project_id}.{work_dataset_id}.{starr_miner_vocab_name}`\n",
    "\"\"\".format_map({'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id,\n",
    "                'starr_miner_vocab_name': starr_miner_vocab_name,\n",
    "                'omop_vocab_dataset_id': omop_vocab_dataset_id})\n",
    "\n",
    "df = client.query(sql).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   n_unique_strings  n_unique_concept_id  n_unique_standard_concept_id\n0            989293               749337                        470656",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>n_unique_strings</th>\n      <th>n_unique_concept_id</th>\n      <th>n_unique_standard_concept_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>989293</td>\n      <td>749337</td>\n      <td>470656</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how the vocab looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "SELECT * \n",
    "FROM\n",
    " `{work_project_id}.{work_dataset_id}.{starr_miner_vocab_name}`\n",
    "LIMIT 5\n",
    "\"\"\".format_map({'work_project_id': work_project_id,\n",
    "                'work_dataset_id': work_dataset_id,\n",
    "                'starr_miner_vocab_name': starr_miner_vocab_name,\n",
    "                'omop_vocab_dataset_id': omop_vocab_dataset_id})\n",
    "\n",
    "df = client.query(sql).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   concept_index  concept_id  standard_concept_id  \\\n0         623722      443343               443343   \n1         655579     4105418              4105418   \n2          37553     4293949             40236190   \n3         108689     4019486              4019486   \n4         747705     4070191              4070191   \n\n                                   lowerstr  \n0                   female genital diseases  \n1                     ability to run uphill  \n2  gg 100/pseudoephedrin 30mg/5ml alc-f syr  \n3                        fibromatous tumour  \n4                        eimeria rajesthani  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>concept_index</th>\n      <th>concept_id</th>\n      <th>standard_concept_id</th>\n      <th>lowerstr</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>623722</td>\n      <td>443343</td>\n      <td>443343</td>\n      <td>female genital diseases</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>655579</td>\n      <td>4105418</td>\n      <td>4105418</td>\n      <td>ability to run uphill</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>37553</td>\n      <td>4293949</td>\n      <td>40236190</td>\n      <td>gg 100/pseudoephedrin 30mg/5ml alc-f syr</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>108689</td>\n      <td>4019486</td>\n      <td>4019486</td>\n      <td>fibromatous tumour</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>747705</td>\n      <td>4070191</td>\n      <td>4070191</td>\n      <td>eimeria rajesthani</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('spacy_env': conda)",
   "language": "python",
   "name": "python_defaultSpec_1596657677909"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}